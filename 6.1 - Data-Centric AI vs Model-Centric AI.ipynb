{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0939681",
   "metadata": {},
   "source": [
    "## Installing software\n",
    "\n",
    "For this lab, you'll need to install [scikit-learn](https://scikit-learn.org/) and [pandas](https://pandas.pydata.org/). If you don't have them installed already, you can install them by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d611c046",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: scikit-learn in /root/miniconda3/envs/utl/lib/python3.11/site-packages (1.4.2)\n",
      "Requirement already satisfied: pandas in /root/miniconda3/envs/utl/lib/python3.11/site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /root/miniconda3/envs/utl/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /root/miniconda3/envs/utl/lib/python3.11/site-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /root/miniconda3/envs/utl/lib/python3.11/site-packages (from scikit-learn) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /root/miniconda3/envs/utl/lib/python3.11/site-packages (from scikit-learn) (3.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/miniconda3/envs/utl/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/miniconda3/envs/utl/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/miniconda3/envs/utl/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda3/envs/utl/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256637ed",
   "metadata": {},
   "source": [
    "# Loading the data\n",
    "\n",
    "First, let's load the train/test sets and take a look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2a5f8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a36d457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>Recent issue contained obscene advertizing</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Love this magazine and service</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>Another great magazine.  Tons of fashion, very...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>My daughter loves this magazine.  I got a subs...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>I didn't order item</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review label\n",
       "840         Recent issue contained obscene advertizing   bad\n",
       "26                      Love this magazine and service  good\n",
       "398  Another great magazine.  Tons of fashion, very...  good\n",
       "375  My daughter loves this magazine.  I got a subs...  good\n",
       "977                                I didn't order item   bad"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('data/reviews_train.csv')\n",
    "test = pd.read_csv('data/reviews_test.csv')\n",
    "\n",
    "test.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1559f174",
   "metadata": {},
   "source": [
    "# Training a baseline model\n",
    "\n",
    "There are many approaches for training a sequence classification model for text data. In this lab, we're giving you code that mirrors what you find if you look up [how to train a text classifier](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html), where we'll train an SVM on [tf-idf](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) features (numeric representations of each text field based on word occurrences)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34589687",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5f9f20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cbe95b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sgd_clf.fit(train['review'], train['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dc7903",
   "metadata": {},
   "source": [
    "## Evaluating model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a4897ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f92e9a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(clf):\n",
    "    pred = clf.predict(test['review'])\n",
    "    acc = metrics.accuracy_score(test['label'], pred)\n",
    "    print(f'Accuracy: {100*acc:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a54a1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.5%\n"
     ]
    }
   ],
   "source": [
    "evaluate(sgd_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd74fea",
   "metadata": {},
   "source": [
    "## Trying another model\n",
    "\n",
    "76% accuracy is not great for this binary classification problem. Can you do better with a different model, or by tuning hyperparameters for the SVM trained with SGD?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1481a624",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "\n",
    "Can you train a more accurate model on the dataset (without changing the dataset)? You might find this [scikit-learn classifier comparison](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html) handy, as well as the [documentation for supervised learning in scikit-learn](https://scikit-learn.org/stable/supervised_learning.html).\n",
    "\n",
    "One idea for a model you could try is a [naive Bayes classifier](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html).\n",
    "\n",
    "You could also try experimenting with different values of the model hyperparameters, perhaps tuning them via a [grid search](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). \n",
    "\n",
    "Or you can even try training multiple different models and [ensembling their predictions](https://scikit-learn.org/stable/modules/ensemble.html#voting-classifier), a strategy often used to win prediction competitions like Kaggle.\n",
    "\n",
    "**Advanced:** If you want to be more ambitious, you could try an even fancier model, like training a Transformer neural network. If you go with that, you'll want to fine-tune a pre-trained model. This [guide from HuggingFace](https://huggingface.co/docs/transformers/training) may be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cd5d16e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.1%\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "import os\n",
    "from transformers import pipeline\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "model = pipeline(task=\"sentiment-analysis\", model=\"finiteautomata/bertweet-base-sentiment-analysis\", device=0)\n",
    "# evaluate your model and see if it does better\n",
    "# than the ones we provided\n",
    "def evaluate(model):\n",
    "    pred = model(test['review'].to_list())\n",
    "    predicted_label = ['good' if p['label'] == 'POS' else 'bad' for p in pred]\n",
    "    acc = metrics.accuracy_score(test['label'], predicted_label)\n",
    "    print(f'Accuracy: {100*acc:.1f}%')\n",
    "    \n",
    "evaluate(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d99b07",
   "metadata": {},
   "source": [
    "## Taking a closer look at the training data\n",
    "\n",
    "Let's actually take a look at some of the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e18569f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Based on all the negative comments about Taste...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I still have not received this.  Obviously I c...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;/tr&gt;The magazine is not worth the cost of sub...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This magazine is basically ads. Kindve worthle...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The only thing I've recieved, so far, is the b...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review label\n",
       "0  Based on all the negative comments about Taste...  good\n",
       "1  I still have not received this.  Obviously I c...   bad\n",
       "2  </tr>The magazine is not worth the cost of sub...  good\n",
       "3  This magazine is basically ads. Kindve worthle...   bad\n",
       "4  The only thing I've recieved, so far, is the b...   bad"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4446d850",
   "metadata": {},
   "source": [
    "Zooming in on one particular data point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02fee5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'review': \"Based on all the negative comments about Taste of Home, I will not subscribeto the magazine. In the past it was a great read.\\nSorry it, too, has gone the 'way of the wind'.<br>o-p28pass4 </br>\", 'label': 'good'}\n"
     ]
    }
   ],
   "source": [
    "print(train.iloc[0].to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1204b6e9",
   "metadata": {},
   "source": [
    "This data point is labeled \"good\", but it's clearly a negative review. Also, it looks like there's some funny HTML stuff at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a1e9b4",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n",
    "Take a look at some more examples in the dataset. Do you notice any patterns with bad data points?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8247251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'review': \"I still have not received this.  Obviously I can't review something I haven't seen.  Where is my order???????\", 'label': 'bad'}\n",
      "{'review': '</tr>The magazine is not worth the cost of subscription.</tr>', 'label': 'good'}\n",
      "{'review': 'This magazine is basically ads. Kindve worthless to me really.', 'label': 'bad'}\n",
      "{'review': \"The only thing I've recieved, so far, is the bill.\\nI know this is [ or was when I last subscribed ] a ten month magazine - but so far not even the usual promotional papers.......\", 'label': 'bad'}\n",
      "{'review': 'The magazines are great, but I never received the golf shoe bag that was supposed to accompany my subscription...<body>', 'label': 'good'}\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "print(train.iloc[1].to_dict())\n",
    "print(train.iloc[2].to_dict())\n",
    "print(train.iloc[3].to_dict())\n",
    "print(train.iloc[4].to_dict())\n",
    "print(train.iloc[5].to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0ea1e0",
   "metadata": {},
   "source": [
    "Answer: The bad points are mostly negative reviews that are labeled as positive. They also contain HTML tags. Meanwhile, the aforementioned kind of bad points tend to have words like 'worth', 'good' but with a 'not' in front of them. This might indicate that the model is not able to pick up on the negation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550571c7",
   "metadata": {},
   "source": [
    "## Issues in the data\n",
    "\n",
    "It looks like there's some funny HTML tags in our dataset, and those datapoints have nonsense labels. Maybe this dataset was collected by scraping the internet, and the HTML wasn't quite parsed correctly in all cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2413e13",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "\n",
    "To address this, a simple approach we might try is to throw out the bad data points, and train our model on only the \"clean\" data.\n",
    "\n",
    "Come up with a simple heuristic to identify data points containing HTML, and filter out the bad data points to create a cleaned training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a51afa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def is_bad_data(review: str) -> bool:\n",
    "    # YOUR CODE HERE\n",
    "    pattern = re.compile('<.*?>')\n",
    "    return bool(pattern.search(review))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a947183c",
   "metadata": {},
   "source": [
    "## Creating the cleaned training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f97f5705",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean = train[~train['review'].map(is_bad_data)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd28595",
   "metadata": {},
   "source": [
    "## Evaluating a model trained on the clean training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "884372b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44f6b554",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf_clean = clone(sgd_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c15194b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sgd_clf_clean.fit(train_clean['review'], train_clean['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125bc7f0",
   "metadata": {},
   "source": [
    "This model should do significantly better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c79defc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.9%\n"
     ]
    }
   ],
   "source": [
    "evaluate(sgd_clf_clean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
